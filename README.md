# Inspect
## App Description
Through interactive gameplay that mirrors real internet content, Inspect teaches users how to detect AI-generated disinformation. 

In three levels of the “true or false” game mode, players determine whether a given AI-generated headline is true or false. In the “which one” mode, users select the more extreme or blatantly false AI-generated video-text combination. Each option in both modes has a corresponding short-form video generated by Sora 2 to better model real-world encounters. After the user selects an option, Inspect gives instant feedback on their performance, which allows the user to learn quickly. The challenges get harder as the user progresses.

Engaging microinteractions keep users interested throughout their learning. An animated eye keeps their attention on the app, and satisfying visual feedback makes common interactions interesting. We stylize the app and add these microinteractions using React and CSS.

Inspect is deployed using Firebase: https://inspect-game.web.app/. We used Firebase’s database and storage features to store questions, user data, and videos; we used React to manage application logic and the user interface.

We include real-world topics to ensure user’s learning transfers well to actual internet content. Also, these topics challenge people to distinguish truth from falsehood regardless of their opinion on the topic. Nevertheless, we separate the more harmless topics in the “true or false” game mode, leaving the more real-world challenges to the “which one” game mode.

Furthermore, for safety, we prevent users from copying the challenge text, and all Sora 2 videos include watermarks.

We intentionally create our challenges using several generative AI tools: OpenAI’s GPT-4.1, to control temperature, or the “creativity” of the model; GPT-5, for structured output; and Sora 2. As a result of using state-of-the-art AI models, our challenges accurately resemble real-world, AI-generated media.

## Idea Inspiration
Democracy needs truth. The rise of online disinformation, exacerbated by AI, threatens the very foundation of our nation. 

With political extremism at an all-time high, false and biased content polarize people's beliefs. Around the 2024 presidential election and the recent death of Charlie Kirk, we saw many of our friends turn to short-form media for their news. While some watched shorts from reliable organizations, many turned to independent and unverified content creators for their information. One time, a friend talked to us about AI, gave coherent points for his argument, but then presented a completely made-up statistic as his justification. When we asked for his source, he smiled in realization, saying “Instagram reels,” a short-form video platform. This trend goes beyond our classmates; people across the world are increasingly turning to online influencers, often with a political agenda, for their news.

Now, AI video generators such as Sora 2 and Veo 3.1 are flooding the internet with disinformation, which we’ve personally seen in our feeds. The sudden rise of these generators necessitates our nation be able to detect falsehood.

If people could better detect disinformation, their votes and opinions would represent thoughts based on truth rather than built upon pillars of nonsense. Inspect teaches people how to distinguish truth from falsehood through interactive, real-world challenges. It protects the truth that democracy rests upon.

Coming up with the idea for Inspect, we chatted with various students in our community about their interests and their problems. Next, we observed their playing of Google’s “Say What You See” game, which teaches image prompting, and noted that they enjoyed the colorful appearance and interactive interface of the game. These observations and conversations served as the original launch point for Inspect. 

In addition, we tested the premise of Inspect by split-screening two pieces of AI-generated content and asking students to select which one they believed was fake. Based on this preliminary testing, we adapted Inspect to include videos, making the app more engaging. Furthermore, we talked to our school community about their motivations for scrolling, and we observed their short-form content preferences, particularly political shorts, to inform our AI challenge creation program. Through conversation with our school community, we made Inspect more fun and relevant to users.

## Technical Challenges
Over the course of building Inspect, we faced numerous technical difficulties. 

Firstly, the initial setup for Firebase, particularly hosting, proved cumbersome, but we ultimately managed to complete the correct command-line setup. Additionally, configuring CORS to give the app access to the videos stored on Firebase also required complex terminal commands. After substantial research, we used the React Router DOM, to turn the laggy screen reloads between questions, modes, and menus into seamless transitions onto the next page.

In addition, we struggled to get the challenges to load properly, but managed to fix the issue by accessing the state, which contains “reactive data” held by the app, after the initial page load.  The issue was that useEffect ran before the state was initialized, so the subsequent code failed to run.

Furthermore, creating the sophisticated microinteractions of the eye was especially challenging; creating and subtly moving the eye all require complex mathematical manipulations, especially since the eye was a SVG, which is defined only by functions.

Also, configuring the model parameters was challenging because certain features were exclusive to specific models. We initially wanted to use GPT-5, the latest model, for everything, but we encountered issues with the temperature parameter, which determines how “creative” the model is. Since we couldn’t vary the temperature of GPT-5, we used the slightly older but still cutting-edge GPT-4.1 model, which allows temperature variation.

## Future Improvements
For the next version of Inspect, we would leverage social media. Instead of having a web app as the primary source of traffic, we could—either as the main medium or as an additional one—we’d post the challenges onto short-form content platforms. This way, we’d directly target the people who are the most likely to view disinformation on a regular basis. We’d have the “true or false” challenges contain videos with headlines and then present whether the headline was true or not at the end. We’d make the “which one” challenges be shorts with two options, each with a video and a sentence; we’d label the more extreme or fake option at the end. The context of these challenges would be the exact same as regular scrolling, ensuring the user’s disinformation detection skills transfer directly.

For this version, we’d use the YouTube Data API, TikTok API, and the Instagram API to post directly onto YouTube Shorts, TikTok, and Instagram Reels—the three most-popular short-form content sites. Instead of a feared, AI-generated disinformation machine that mass-distributes disinformation, we’d make an educational machine that pumps out educational challenges to teach people to detect that very same disinformation.

On another note—and moving back to the web-based version of Inspect—we would add personalized learning to the web app itself, thereby making the learning process more efficient. This way, users will not only experience increasing difficulty, but also have tailored challenges on their weak points (e.g. maybe some user struggles with tech headlines). Because we already have an AI system to generate challenges, we could even generate custom challenges for each individual user. Additionally, the implementation of this adaptive learning algorithm wouldn’t require much more data since Inspect already tracks user progress on Firebase.

This adaptive learning system could implement an Elo-based algorithm, where, if a user gets a challenge correct, the Elo (difficulty in this case) of the challenge decreases while the Elo (skill in this case) of the user increases, and vice versa. Then, Inspect could have leaderboards of users, ranked by Elo, and implement other gamification features. For example, users could get a streak of gaining Elo, or they could move up in “ranking” by consistently playing on the app. These features would make Inspect even more engaging!

What did you learn or take away from participating in the Congressional App Challenge? (400 max)
Over the course of building Inspect, we’ve learned a ton: we’ve learned how to manage and plan a large-scale project; we’ve learned how to test our ideas to ensure the app would have a true impact on our community; and we’ve learned a ton of industry technologies during the development process.

I (Isaac) finally switched from plain Javascript to the much more powerful framework of React. In the process, I learned the file format of a React app and how to deploy them using Firebase. I also learned how to integrate Firebase features across a React app. In addition, I (Santiago) created the complex microinteractions of the eye, learning how to make SVGs and practicing a ton of advanced math. We also learned how to use Firebase storage to store videos and gained significant practice connecting the user to the backend.

I (Santiago) learned how to make clean, human-friendly user interfaces, and I became a better programmer because of it. In addition, I grew as a teacher, through working on the challenge of teaching difficult, instinctual skills, digitally, using a pre-made curriculum. The challenge of teaching without being able to answer questions live—in contrast to my usual tutoring—created a unique style of interactive education visible in Inspect.

The design process also taught us how to make an app more fun while keeping an human-friendly design. The microinteractions such as the highlight before you click and the moving eye were both fun to implement and deepened our knowledge of CSS and React.

